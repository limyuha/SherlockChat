import json
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import os

# 1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 2ï¸âƒ£ í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SherlockChat - ì¶”ë¦¬ ê²Œì„", layout="centered")

# 3ï¸âƒ£ ì‚¬ê±´ ë°ì´í„° ë¡œë“œ
with open("cases/case1.json", "r", encoding="utf-8") as f:
    case = json.load(f)

st.title(f"ğŸ•µï¸â€â™‚ï¸ {case['title']}")
st.write(case["summary"])

st.markdown("### ğŸ” ë‹¨ì„œ ëª©ë¡")
for c in case["clues"]:
    st.write(f"- {c}")

st.markdown("---")

# 4ï¸âƒ£ ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ğŸ§© ì‚¬ê±´ ë¸Œë¦¬í•‘ ì™„ë£Œ. ë‹¹ì‹ ì˜ ì¶”ë¦¬ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”."}
    ]
    st.session_state.found_clues = set()
    st.session_state.game_over = False

# 5ï¸âƒ£ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        st.markdown(f"**AI:** {msg['content']}")
    else:
        st.markdown(f"**ğŸ‘¤ ë‹¹ì‹ :** {msg['content']}")

# 6ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥
user_input = st.text_input("ğŸ•µï¸ ì¶”ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")

# 7ï¸âƒ£ ì „ì†¡ ë²„íŠ¼ í´ë¦­ ì‹œ
if st.button("ì „ì†¡") and not st.session_state.game_over:
    if user_input.strip():
        user_message = user_input.strip()
        st.session_state.messages.append({"role": "user", "content": user_message})

        # ğŸ¯ 1ï¸âƒ£ ë‹¨ì„œ ë§¤ì¹­
        found_location = None
        for location, has_clue in case.get("locations", {}).items():
            if location in user_message:
                found_location = (location, has_clue)
                break

        # ğŸ¯ 2ï¸âƒ£ ë‹¨ì„œ ê²°ê³¼
        if found_location:
            loc_name, has_clue = found_location
            if has_clue:
                if loc_name not in st.session_state.found_clues:
                    st.session_state.found_clues.add(loc_name)
                    ai_reply = f"ğŸ” ì¢‹ì•„ìš”! ë‹¹ì‹ ì˜ ì¶”ë¦¬ê°€ ë§ì•˜ì–´ìš”. **{loc_name} ê·¼ì²˜ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì„œê°€ ë°œê²¬ëì–´ìš”.**"
                else:
                    ai_reply = f"ğŸ“ ì´ë¯¸ **{loc_name}** ê·¼ì²˜ ë‹¨ì„œë¥¼ ì°¾ì•˜ì–´ìš”. ë‹¤ë¥¸ ê³³ë„ ì‚´í´ë³´ì£ ."
            else:
                ai_reply = f"âŒ **{loc_name}** ê·¼ì²˜ì—ì„œëŠ” ì•„ë¬´ ë‹¨ì„œë„ ë°œê²¬ë˜ì§€ ì•Šì•˜ì–´ìš”."
        else:
            # ğŸ¯ 3ï¸âƒ£ ì¼ë°˜ ëŒ€í™” (GPT ì‚¬ìš©)
            with st.spinner("AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ì¶”ë¦¬ ë³´ì¡° íƒì • AI ì…œë¡ì´ì•¼. ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´."},
                        {"role": "user", "content": user_message}
                    ],
                    temperature=0.8,
                )
                ai_reply = response.choices[0].message.content

        # ğŸ¯ 4ï¸âƒ£ ë‹¨ì„œ ëª¨ë‘ ì°¾ì•˜ëŠ”ì§€ í™•ì¸
        all_true_clues = {k for k, v in case["locations"].items() if v}
        if st.session_state.found_clues == all_true_clues:
            ai_reply += "\n\nğŸ‰ ëª¨ë“  ë‹¨ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! ê²°ë§ì´ ë°í˜€ì§‘ë‹ˆë‹¤...\n\n" + case["ending"]
            st.session_state.game_over = True

        st.session_state.messages.append({"role": "assistant", "content": ai_reply})
        st.rerun()
