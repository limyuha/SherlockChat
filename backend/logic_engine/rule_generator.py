import json, os, re
from collections import Counter

# âœ… ì¡°ì‚¬Â·ë¶ˆìš©ì–´ ì œê±°ìš© ë¦¬ìŠ¤íŠ¸
STOPWORDS = {
    "ê·¸ë¦¬ê³ ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ìˆë‹¤", "í•˜ì˜€ë‹¤", "í–ˆë‹¤", "ê²ƒì´ë‹¤",
    "ì‚¬ê±´", "ì¸ë¬¼", "ë‹¨ì„œ", "ì´", "ê°€", "ì€", "ëŠ”", "ì„", "ë¥¼", "ì˜",
    "ì™€", "ê³¼", "ì—ì„œ", "ì—ê²Œ", "í•œ", "ë˜ì—ˆë‹¤", "í–ˆë‹¤", "í•œë‹¤",
    "ì—†ìŒ", "ìˆìŒ", "ì…ë‹ˆë‹¤", "ì´ì—ˆ", "ì´ì—ˆë‹¤", "í•˜ë©°"
}

# âœ… ì¡°ì‚¬ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
def clean_token(token: str):
    token = re.sub(r"[^ê°€-í£A-Za-z0-9]", "", token)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    token = re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ê³¼|ì™€|ê³¼ì˜|ì˜€ë‹¤|ì˜€ë‹¤)$", "", token)
    return token.strip()

# âœ… í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords(text):
    tokens = re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", text)
    cleaned = [clean_token(t) for t in tokens if t not in STOPWORDS]
    cleaned = [t for t in cleaned if len(t) >= 2 and not re.search(r"^[0-9]+$", t)]  # ìˆ«ì ì œì™¸
    return cleaned

# âœ… ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ â†’ ë¬¸ìì—´ ì•ˆì „ ë³€í™˜
def safe_text(value):
    if isinstance(value, (dict, list)):
        return json.dumps(value, ensure_ascii=False)
    return str(value)

# âœ… ê·œì¹™ ìƒì„± ë¡œì§
def generate_rules_from_case(case_file):
    with open(case_file, "r", encoding="utf-8") as f:
        case_data = json.load(f)

    overview = safe_text(case_data.get("case_overview", ""))
    solution = safe_text(case_data.get("solution", ""))
    characters = " ".join(safe_text(c.get("description", "")) for c in case_data.get("characters", []))
    evidence = " ".join(safe_text(e.get("description", "")) for e in case_data.get("evidence", []))

    all_text = " ".join([overview, solution, characters, evidence])
    keywords = extract_keywords(all_text)

    # ğŸ”¹ ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ ìƒìœ„ ì¶”ì¶œ
    freq = Counter(keywords)
    top_keywords = [w for w, count in freq.most_common(20) if count > 1 and len(w) >= 2]

    rules = []
    for kw in top_keywords:
        rules.append({
            "pattern": kw,
            "verdict": "yes",
            "evidence": f"'{kw}'ëŠ” ì‚¬ê±´ì˜ í•µì‹¬ ë‹¨ì„œì…ë‹ˆë‹¤."
        })

    # ğŸ”¹ ì‚¬ê±´ ì „ë°˜ ê³µí†µ ë¶€ì • ê·œì¹™ ì¶”ê°€
    rules += [
        {"pattern": "ì‚´í•´|ë²”ì¸|í‰ê¸°", "verdict": "no", "evidence": "ì´ ì‚¬ê±´ì€ ë‹¨ìˆœ ì‚´ì¸ì‚¬ê±´ì´ ì•„ë‹™ë‹ˆë‹¤."},
        {"pattern": "ê¸°ì–µ|ì‹¤í—˜|ë£¨í”„", "verdict": "yes", "evidence": "ì´ ì‚¬ê±´ì€ ì‹¤í—˜ê³¼ ê¸°ì–µ ì¡°ì‘ê³¼ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤."}
    ]

    base = os.path.basename(case_file).replace(".json", "")
    output_dir = os.path.join(os.path.dirname(__file__), "rules")
    os.makedirs(output_dir, exist_ok=True)
    out_path = os.path.join(output_dir, f"{base}_rules.json")

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(rules, f, ensure_ascii=False, indent=2)

    print(f"âœ… {out_path} ìƒì„± ì™„ë£Œ (ê·œì¹™ {len(rules)}ê°œ)")
    return out_path

# âœ… ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    base_dir = os.path.dirname(os.path.dirname(__file__))
    cases_dir = os.path.join(base_dir, "cases")

    for fname in ["case_high.json", "case_mid.json", "case_low.json"]:
        path = os.path.join(cases_dir, fname)
        if os.path.exists(path):
            generate_rules_from_case(path)
        else:
            print(f"âš ï¸ {fname} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
